---
title: "Proyecto predicción de precios en viviendas"
output: html_notebook
---

Importación y carga de paquetes

```{r}
library(tidyverse)
library(caret)
library(data.table)
library(ggplot2)
library(dplyr)
library(corrplot)
library(psych)
library(randomForest)
library(Metrics)
```


Carga de los datos (Tarea 0)

```{r}
train_df <- read_csv('./data/train.csv')
test_df <- read_csv('./data/test.csv')

```

#Visualización de los datos

Vamos a observar las primeras entradas de nuestro conjunto de datos para conocer un poco más de información sobre
el dataset.

```{r}
train_df %>% head()
```

Número de filas y columnas del conjunto de entrenamiento.
```{r}
nrow(train_df)
ncol(train_df)
```

Número de filas y columnas del conjunto de prueba.
```{r}
nrow(test_df)
ncol(test_df)
```

##Preprocesamiento.

#Eliminación de atributos con más de un 10% de entradas con valor NA. (Tarea 1)

Primero obtendremos una tabla que nos muestre cuantos valores NA existen para cada columna.
```{r}
na_count <- sapply(train_df, function(y) sum((is.na(y))))
na_count <- data.frame(na_count)
```

Ahora procederemos a eliminar las columnas que tengan más de un 10% de entradas con valor NA

```{r}
columns_na <- na_count %>% filter((na_count/nrow(train_df)*100) > 10) %>% rownames()
```

Por último, eliminaremos estas columnas tanto de nuestro conjunto de entrenamiento como en el de prueba.

```{r}
train_df <- train_df[,!(names(train_df) %in% columns_na)]
test_df <- test_df[,!(names(test_df) %in% columns_na)]
```
#Rellenar campos con valor NA. (Tarea 3)

Para todos los valores NA restantes, los modificaremos por las valores más frecuentes o con la media.

```{r}
na_modified <- function(x) {
  if (is.numeric(x)) {
    x[is.na(x)] <- mean(x, na.rm = TRUE)
    x
  } else {
    x[is.na(x)] <- names(which.max(table(x)))
    x
  }
}

train_df <- as.data.frame(lapply(train_df,na_modified))
test_df <- as.data.frame(lapply(test_df,na_modified))
```

## Eliminación de variables no relevantes mediante correlación (Tarea 12)

### NUMÉRICAS

```{r}
train_df_nums <- select_if(train_df, is.numeric)
train_df_not_nums <- select_if(train_df, negate(is.numeric))
test_df_nums <- select_if(test_df, is.numeric)
test_df_not_nums <- select_if(test_df, negate(is.numeric))
```

```{r}

train_cor <- cor(train_df_nums[ , colnames(train_df_nums) != "SalePrice"],
                train_df_nums$SalePrice)
```

```{r}
corrplot(train_cor,
         cl.pos='n',
         insig = 'p-value')
```
```{r}
cor_coef_df <- as.data.frame(train_cor) %>% 
    rename('abs_cor_coef' = V1) %>%
    mutate(abs_cor_coef = abs(abs_cor_coef))
cor_coef_df
```
```{r}
drop_columns_less_20 <- cor_coef_df   %>% filter(abs_cor_coef <0.2)
drop_columns_less_20
```
```{r}
#bigger_threshold <- cor_coef_df > 0.2
bigger_threshold <- replace(cor_coef_df, cor_coef_df<0.2, "red")
bigger_threshold <- replace(bigger_threshold, cor_coef_df>0.2, "green")
bigger_threshold[,1]
```

```{r}
col_names <- row.names(cor_coef_df)
```

```{r}
df <- as.data.frame(cor_coef_df)
```


```{r}
ggplot(df
       , aes(x=col_names, y=abs_cor_coef, fill = col_names)
       ) + 
  scale_fill_manual(
    breaks = c(col_names),
    values=c(bigger_threshold[,1])) +
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 70, vjust = 0.85, hjust=1))
```
```{r}
train_df

```

```{r}
row_names_less_20 <- (row.names(drop_columns_less_20))
row_names_less_20 <- row_names_less_20[row_names_less_20 != "Id"]
train_df <- train_df %>% select(-row_names_less_20)
test_df <- test_df %>% select(-row_names_less_20)
```


Eliminación de variables que no aportan información al algoritmo (Tarea 5)

Comprobamos cuántos valores únicos tiene cada columna de tipo string.


```{r}
unique_count <- as.data.frame(sapply(train_df_not_nums, function(x) length(unique(x)))) %>% 
   rename('value' = 'sapply(train_df_not_nums, function(x) length(unique(x)))')

uniques_col_names <- row.names(unique_count)
threshold <- 8
uniques_threshold <- replace(unique_count, unique_count>=threshold, "red")
uniques_threshold <- replace(uniques_threshold, uniques_threshold<threshold, "green")

ggplot(unique_count
       , aes(x=uniques_col_names, y=value, fill=uniques_col_names)
       ) + 
  scale_fill_manual(
    breaks = c(uniques_col_names),
    values=c(uniques_threshold[,1])) +
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 70, vjust = 0.85, hjust=1))
```
```{r}
more_than_threshold <- unique_count %>% filter(value >= threshold ) %>% rownames()
more_than_threshold
```
```{r}
# Esto debería hacerse con train y test, pero parece que no tienen las mismas dimensiones, por eso lo hago con las variables categóricas solamente
test_df <- test_df %>% mutate(SalePrice = -1);
merged_df <- rbind(train_df, test_df) %>% select(-more_than_threshold)

dummy_vars <- dummyVars(" ~ .", data = merged_df)
merged_df <- data.frame(predict(dummy_vars, newdata = merged_df))

# Separar train y test, para cuando se puedan utilizar con la variable id
train_df <- merged_df %>% filter(Id < 1461)
test_df <- merged_df %>% filter(Id > 1460) %>% select(-SalePrice)

#Como hemos creado muchas columnas vamos a utilizar RFE(Random Feature Elimination) para reducir la dimensionalidad
sales_prices <- train_df$SalePrice
train_df <- train_df %>% select(-c("Id", "SalePrice"))
test_df <- test_df %>% select(-Id)

#Crear train y test para RFE
data_partition <- createDataPartition(sales_prices, p = .70, list = FALSE)
RFE_X_train <- train_df[data_partition,]
RFE_X_test <- train_df[-data_partition,]
RFE_Y_train <- sales_prices[data_partition]
RFE_Y_test <- sales_prices[-data_partition]

num_variables <- c(80, 100, 120, 140)
control <- rfeControl(functions = rfFuncs, method = "repeatedcv", repeats = 3, number = 5)
rfe <- rfe(x = RFE_X_train, y = RFE_Y_train, sizes = num_variables, rfeControl = control)
ggplot(rfe)
```
```{r}
columns <- predictors(rfe)

train_df <- as.data.frame(train_df)
test_df <- as.data.frame(test_df)

sales_prices_df <- as.data.frame(sales_prices) %>% rename(SalePrice = sales_prices)
train_df <- cbind(train_df, sales_prices_df) %>% select(append(columns, 'SalePrice'))
test_df <- test_df %>% select(columns)
```

```{r}
train_df_training <- train_df %>% select(-SalePrice)
```

```{r}
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
```

```{r}
svm_Linear <- train(x=train_df_training, y=train_df$SalePrice, method = "svmLinear",
    trControl=trctrl,
#    preProcess = c("center", "scale"),
    tuneLength = 10)

```

```{r}
svm_Linear
```

```{r}
test_pred <- predict(svm_Linear, newdata = test_df)
test_pred
```


```{r}
svm_radial <- train(x=train_df_training, y=train_df$SalePrice, method = "svmRadial",
    trControl=trctrl,
    preProcess = c("center", "scale"),
    tuneLength = 10)

```

```{r}
svm_radial
```

```{r}
test_pred <- predict(svm_radial, newdata = test_df)
rmsle(test_df, test_pred)
```

```{r}
svm_poly <- train(x=train_df_training, y=train_df$SalePrice, method = "svmPoly",
    trControl=trctrl,
    preProcess = c("center", "scale"),
    tuneLength = 4)

```

```{r}
svm_poly
```

```{r}
test_pred_aux <- as.data.frame(test_pred)
test_pred_aux$Id <- rownames(test_df)

```

